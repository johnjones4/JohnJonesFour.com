---

title:  "Algorithmic Journalism"
description: "In hindsight of this election, there have been countless articles on how social media, so much more than ever before, affected the outcome of the race."
background_image: hearst.jpg
---

In hindsight of this election, there have been countless articles on how social media, so much more than ever before, affected the outcome of the race. And while the deeper causes of this election have much more to do with the evolution of this country over the past several decades, there is room for a conversation over how the ever growing study of artificial intelligence (AI) in computer science now has enormous affect on how individuals receive news and information online.

A few months ago, Facebook admitted it had been editorially managing its trending content list rather than allowing an algorithm to decide as many suspected. With validated outrage among those who felt there was a bias in Facebook's trends, the tech company introduced a new, purely AI-backed trending recommendations system and within days it was [promoting fake news](https://www.washingtonpost.com/news/the-intersect/wp/2016/08/29/a-fake-headline-about-megyn-kelly-was-trending-on-facebook/). Despite promises by Facebook and other social platforms to build better monitoring tools for junk content, the fake news continued to the point that [a few teens in the Balkans collected a tidy sum in ad revenue](https://www.buzzfeed.com/craigsilverman/how-macedonia-became-a-global-hub-for-pro-trump-misinfo?utm_term=.mxGDVWA5V#.pqjR8BQD8) from both lifted and fictitious pro-Trump/anti-Clinton content with the bulk of their traffic coming from social media.

We see now how any content on social media - fake or real - and the artificial intelligence backed algorithms the platforms employ to decide what content users see has contributed to not only the outcome of the election but also the outpouring of surprise and rebuke at the results. The _Wall Street Journal_'s May posting of _[Blue Feed, Red Feed](http://graphics.wsj.com/blue-feed-red-feed/)_ again shows us what an echo chamber these feeds have become whereby users constantly see only what the platforms think they want to see. (If it's human nature to want your opinions validated, then that's something these platforms have been unequivocally successful at delivering.)

With successes in AI such as Google now being able to [redirect behavior shown to be at risk for ISIS recruitment](https://www.wired.com/2016/09/googles-clever-plan-stop-aspiring-isis-recruits/) and failures such as Microsoft's Twitter bot [breaking down into a racist tirade](http://www.nytimes.com/2016/03/25/technology/microsoft-created-a-twitter-bot-to-learn-from-users-it-quickly-became-a-racist-jerk.html), 2016 has been quite the year for artificial intelligence and it will only continue to grow in how it impacts or our lives. So much so that outgoing President Obama is [commenting on the issue](https://www.wired.com/2016/10/president-obama-mit-joi-ito-interview/) that we must be careful how we design these systems and apply them across society. For it is not his fear of a Terminitor-esc robot uprising, but a fear that an isolated handful of brilliants minds are making decisions that have vast societal and economic impact without the input of others.

Newspaper publisher William Randolph Hearst's famous quip, "You furnish the pictures and I'll furnish the war," is applicable once again in a new way. This time, it is the technologists who wield the power to start the war and virtually everyone else who provides the pictures. We've allowed the algorithms that Noam Chomsky [pointed out](https://www.technologyreview.com/s/423917/unthinking-machines/) five years ago have only rudimentary understanding of semantics but no understanding of cultural value decide what we read and where we place our focus. A key part of Trump's rise and even others who mocked or profited from his rise was those individuals' ability to use strong rhetoric and game these platforms to raise their messages and content. And our own behavior seems to mimic these algorithms as we obsess more over polls than we do positions.

In a way, this is not new. The rise of cable news years ago and those networks' eventual political polarization sparked a similar debate whereby individuals would choose the network that most aligned with their preexisting beliefs and simply consume whatever content was delivered. But the difference now is that what was once a human job, editorially selecting the stories and information deemed "fit to print," is now largely the job of computers that have an understanding of words but not of decency. Because of that we have media platforms that only mimic the dividedness we see in our lives where we hear "I don't know a single Trump voter" or "I don't know a single Clinton voter."

If we are as divided as this election seems to indicate, then must endeavor to tell the real, human stories of the divided and use technology to connect rather than to isolate. We must tell the story of the small towns across the country that feel left behind by progress and the economy. We must tell the story of the immigrant children who come to their teacher crying for fear of deportation. And we must find a way for each side to hear and understand each other. Those are the stories we must build algorithms to understand.
